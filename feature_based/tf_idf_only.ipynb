{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYkaJZbH9i7X",
        "outputId": "7618d403-350f-4749-cf60-3c2687efa86b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mord as m\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import mutual_info_regression, SelectKBest, chi2\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, cohen_kappa_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from functools import partial\n",
        "\n",
        "# Definição do Tipo de Análise:\n",
        "# Valores de 0 a 4: Competências do ENEM (C1 a C5)\n",
        "# Valor 5: Nota final (soma das competências)\n",
        "REFERENCE_CONCEPT = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPRHizpc833A"
      },
      "source": [
        "# Carregamento do dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxYj622Z833B",
        "outputId": "9cffd7e9-38f4-4af4-cbe7-7ead76a5ba7b"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"../corpus/\"\n",
        "DATASET_NAME = \"-00000-of-00001.parquet\"\n",
        "DIVISIONS = (\"train\", \"validation\", \"test\")\n",
        "def target_dataset_path(target: str):\n",
        "    if target in DIVISIONS:\n",
        "        return DATASET_PATH + target + DATASET_NAME\n",
        "    else:\n",
        "        raise ValueError(\"ERROR: Invalid target for dataset.\")\n",
        "\n",
        "datasets_dict = {}\n",
        "\n",
        "for division in DIVISIONS:\n",
        "    file_path = target_dataset_path(division)\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Arquivo não encontrado: {file_path}\")\n",
        "    df = pd.read_parquet(file_path, engine='pyarrow')\n",
        "    datasets_dict[division] = Dataset.from_pandas(df)\n",
        "\n",
        "dataset_filtrado = DatasetDict(datasets_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHPaxcKnOeIY"
      },
      "outputs": [],
      "source": [
        "# Mapeamento de notas para competências (não aplicável à nota final)\n",
        "grade_mapping = {\n",
        "    0: 0,\n",
        "    40: 1,\n",
        "    80: 2,\n",
        "    120: 3,\n",
        "    160: 4,\n",
        "    200: 5,\n",
        "}\n",
        "\n",
        "def create_label(row):\n",
        "  if REFERENCE_CONCEPT == 5:\n",
        "    return {\"label\": row[\"grades\"][-1]}\n",
        "  else:\n",
        "    grade = row[\"grades\"][REFERENCE_CONCEPT]\n",
        "    return {\"label\": grade_mapping[grade]}\n",
        "\n",
        "dataset = dataset_filtrado.map(create_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J77AOh72833F"
      },
      "source": [
        "# Função para Calcular a Acurácia do ENEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1L9kz_h833F"
      },
      "outputs": [],
      "source": [
        "def enem_accuracy_score(true_values, predicted_values):\n",
        "    \"\"\"Calcula acurácia no padrão ENEM (diferença <= 80 pontos)\"\"\"\n",
        "    if REFERENCE_CONCEPT == 5:\n",
        "      limite_pontos = 80\n",
        "    else:\n",
        "      limite_pontos = 2\n",
        "    assert len(true_values) == len(predicted_values), \"Mismatched length between true and predicted values.\"  # Verifica se cada valor predito tem um correspondente pra calcular a diferença\n",
        "\n",
        "    non_divergent_count = sum([1 for t, p in zip(true_values, predicted_values) if abs(t - p) <= limite_pontos])\n",
        "\n",
        "    return non_divergent_count / len(true_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTfMwrrGYAAR"
      },
      "source": [
        "# Função regression_report inspirada na classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUHdV0SyYFf9"
      },
      "outputs": [],
      "source": [
        "def regression_report(y_true, y_pred):\n",
        "    \"\"\"Relatório completo de métricas de regressão\"\"\"\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    enem_acc = enem_accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # QWK precisa transformar as notas em inteiros\n",
        "    y_true_rounded = np.round(y_true).astype(int)\n",
        "    y_pred_rounded = np.round(y_pred).astype(int)\n",
        "\n",
        "    qwk = cohen_kappa_score(y_true_rounded, y_pred_rounded, weights=\"quadratic\")\n",
        "\n",
        "    print(\"Regression Report:\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "    print(f\"ENEM Accuracy Score: {enem_acc:.2f}\")\n",
        "    print(f\"Quadratic Weighted Kappa (QWK): {qwk:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JSSgVsXe2th"
      },
      "source": [
        "# Pré-Processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O3gNL7ee5t5"
      },
      "outputs": [],
      "source": [
        "# Configuração para TF-IDF\n",
        "stop_words = stopwords.words(\"portuguese\")\n",
        "X_train = dataset[\"train\"][\"essay_text\"]\n",
        "X_test = dataset[\"test\"][\"essay_text\"]\n",
        "y_train = np.array(dataset[\"train\"][\"label\"]).reshape(-1)\n",
        "y_test = np.array(dataset[\"test\"][\"label\"]).reshape(-1)\n",
        "\n",
        "if REFERENCE_CONCEPT == 0:\n",
        "    # C1 (Gramática): Caracteres (mantém stop words)\n",
        "    params = {'sublinear_tf': True, 'analyzer': 'char_wb', 'min_df': 5, 'ngram_range': (3, 5), 'max_features': 5000}\n",
        "\n",
        "elif REFERENCE_CONCEPT == 3:\n",
        "    # C4 (Coesão): Palavras + Conectivos (mantém stop words)\n",
        "    params = {'sublinear_tf': True, 'min_df': 5, 'ngram_range': (1, 3)}\n",
        "\n",
        "else:\n",
        "    # C2, C3, C5 (Tema/Argumentação): Palavras sem stop words\n",
        "    params = {'sublinear_tf': True, 'min_df': 5, 'ngram_range': (1, 2), 'stop_words': stop_words}\n",
        "\n",
        "if REFERENCE_CONCEPT == 0: \n",
        "    k_best_val = 500 \n",
        "else:\n",
        "    k_best_val = 2000 \n",
        "\n",
        "# Pipeline para regressão\n",
        "preprocessador = make_pipeline(\n",
        "    TfidfVectorizer(**params),\n",
        "    SelectKBest(score_func=partial(mutual_info_regression, random_state=1), k=k_best_val),\n",
        "    Normalizer(norm='l2')\n",
        ")\n",
        "X_train_transf = preprocessador.fit_transform(X_train, y_train)\n",
        "\n",
        "# Pipeline para classificação (usado apenas para competências)\n",
        "if REFERENCE_CONCEPT != 5:\n",
        "    preprocessador_clf = make_pipeline(\n",
        "        TfidfVectorizer(**params),\n",
        "        SelectKBest(score_func=chi2, k=k_best_val),\n",
        "        Normalizer(norm='l2')\n",
        "    )\n",
        "    X_train_clf = preprocessador_clf.fit_transform(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZrC6Ic-ghOB"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTas0rsQQ08N"
      },
      "outputs": [],
      "source": [
        "# Dicionário de modelos\n",
        "modelos = {\n",
        "    # Modelos de Regressão\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Regressao Linear\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Random Forest Regression\": RandomForestRegressor(random_state=1),\n",
        "    \"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(random_state=1),\n",
        "    \"SVR\": SVR(),\n",
        "    \"MLP\": MLPRegressor(random_state=1, max_iter=1000),\n",
        "    \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=1),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=1),\n",
        "\n",
        "    # Modelos de regressão ordinal (apenas para competências)\n",
        "    \"Ordinal Regression LogisticAT\": m.LogisticAT(alpha=1.0),\n",
        "    \"Ordinal Regression LogisticIT\": m.LogisticIT(alpha=1.0),\n",
        "    \"Ordinal Regression OrdinalRidge\": m.OrdinalRidge(),\n",
        "    \"Least Absolute Deviation (LAD)\": m.LAD(random_state=1) # É como uma regressão linear, mas utiliza o erro absoluto em vez do erro quadrático\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f99vVCchIj6"
      },
      "source": [
        "# Treinamento e Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiyhhdyhHzJ",
        "outputId": "b05e0222-624e-4ce7-fdfd-86da0bf0877a"
      },
      "outputs": [],
      "source": [
        "print(f\"++++++++++++ ANÁLISE DA {'NOTA FINAL' if REFERENCE_CONCEPT == 5 else f'COMPETÊNCIA {REFERENCE_CONCEPT + 1}'} ++++++++++++\")\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "  if REFERENCE_CONCEPT == 5 and (nome.startswith(\"Ordinal Regression\") or nome == \"Least Absolute Deviation (LAD)\"):\n",
        "        continue  # Pula esses modelos se estiver avaliando a nota final porque mord não funciona sem o mapeamento\n",
        "\n",
        "  # Treinamento especial para HistGradientBoosting (requer array denso)\n",
        "  if nome == \"HistGradientBoostingRegressor\":\n",
        "    X_train_transf_dense = X_train_transf.toarray()\n",
        "    X_test_transf_dense = (preprocessador.transform(X_test)).toarray()\n",
        "    modelo.fit(X_train_transf_dense, y_train)\n",
        "    y_pred = modelo.predict(X_test_transf_dense)\n",
        "  else:\n",
        "    modelo.fit(X_train_transf, y_train)\n",
        "    y_pred = modelo.predict(preprocessador.transform(X_test))\n",
        "\n",
        "  print(f\"****  Modelo: {nome} ****\")\n",
        "  regression_report(y_test, y_pred)\n",
        "\n",
        "  if REFERENCE_CONCEPT != 5:\n",
        "        y_pred_round = np.round(y_pred).astype(int)\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred_round, zero_division=0))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(y_test, y_pred_round))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxTQBobB38Vp"
      },
      "source": [
        "# Classificação (Somente para Competências)\n",
        "\n",
        "\n",
        "SVC é a implementação do SVM para problemas de classificação\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yRpW_mR4EWM"
      },
      "outputs": [],
      "source": [
        "if REFERENCE_CONCEPT != 5:\n",
        "  print(\"Otimização de SVC para Classificação:\")\n",
        "  param_grid = {'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10, 100]}\n",
        "  grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "  grid_search.fit(X_train_clf, y_train)\n",
        "\n",
        "  y_pred_clf = grid_search.predict(preprocessador_clf.transform(X_test))\n",
        "  print(\"\\nMelhores parâmetros:\", grid_search.best_params_)\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred_clf))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
